import torch 

CONFIG_NAME = "ConfigName"
VOCABULARY_SIZE = "VocabularySize"

CONTEXT_LENGTH = "ContextLength"
EMBEDDING_DIMENSION = "EmbeddingDimension"
N_HEADS = "NumberOfHeads"
N_LAYERS = "NumberOfLayers"
DROPOUT_EMBEDDING_RATE = "EmbeddingDropoutRate"
DROPOUT_ATTENTION_RATE = "AttentionDropoutRate"
DROPOUT_SHORTCUT_RATE = "TransformerDropoutRate"
QKV_BIAS = "QKVBias"
DEFAULT_DATA_TYPE = "DefaultDataType"

TOKENIZER_TYPE = "TokenizerType"
TOKENIZER_NAME = "TokenizerName"


################################
# CONV_ENG_LC_16K
################################


#26_682_720
CONV_ENG_LC_16K_CONFIG_XS_512_6L_12H_480E = {
    CONFIG_NAME: "CONV_ENG_LC_16K_CONFIG_XS_512_6L_12H_480E",
    VOCABULARY_SIZE: 16000,
    CONTEXT_LENGTH: 512,
    EMBEDDING_DIMENSION: 480,
    N_HEADS: 12,
    N_LAYERS: 6,
    DROPOUT_EMBEDDING_RATE: 0,
    DROPOUT_ATTENTION_RATE: 0,
    DROPOUT_SHORTCUT_RATE: 0,
    QKV_BIAS: False,
    DEFAULT_DATA_TYPE: torch.bfloat16,
    TOKENIZER_TYPE: "sentencepiece",
    TOKENIZER_NAME: "conversational-english-16k-lc-16000"
}

################################
# CONV_ENG_LC_12K
################################


#22_842_720
CONV_ENG_LC_12K_CONFIG_XS_512_6L_12H_480E = {
    CONFIG_NAME: "CONV_ENG_LC_12K_CONFIG_XS_512_6L_12H_480E",
    VOCABULARY_SIZE: 12000,
    CONTEXT_LENGTH: 512,
    EMBEDDING_DIMENSION: 480,
    N_HEADS: 12,
    N_LAYERS: 6,
    DROPOUT_EMBEDDING_RATE: 0,
    DROPOUT_ATTENTION_RATE: 0,
    DROPOUT_SHORTCUT_RATE: 0,
    QKV_BIAS: False,
    DEFAULT_DATA_TYPE: torch.bfloat16,
    TOKENIZER_TYPE: "sentencepiece",
    TOKENIZER_NAME: "conversational-english-12k-lc-12000"
}

#19_835_085
CONV_ENG_LC_12K_CONFIG_XS_300_12L_15H_345E = {
    CONFIG_NAME: "CONV_ENG_LC_12K_CONFIG_XS_300_12L_15H_345E",
    VOCABULARY_SIZE: 12000,
    CONTEXT_LENGTH: 300,
    EMBEDDING_DIMENSION: 345,
    N_HEADS: 15,
    N_LAYERS: 12,
    DROPOUT_EMBEDDING_RATE: 0,
    DROPOUT_ATTENTION_RATE: 0,
    DROPOUT_SHORTCUT_RATE: 0,
    QKV_BIAS: False,
    DEFAULT_DATA_TYPE: torch.bfloat16,
    TOKENIZER_TYPE: "sentencepiece",
    TOKENIZER_NAME: "conversational-english-12k-lc-12000"
}

#31_286_325
CONV_ENG_LC_12K_CONFIG_XS_300_24L_15H_345E = {
    CONFIG_NAME: "CONV_ENG_LC_12K_CONFIG_XS_300_24L_15H_345E",
    VOCABULARY_SIZE: 12000,
    CONTEXT_LENGTH: 300,
    EMBEDDING_DIMENSION: 345,
    N_HEADS: 15,
    N_LAYERS: 24,
    DROPOUT_EMBEDDING_RATE: 0,
    DROPOUT_ATTENTION_RATE: 0,
    DROPOUT_SHORTCUT_RATE: 0,
    QKV_BIAS: False,
    DEFAULT_DATA_TYPE: torch.bfloat16,
    TOKENIZER_TYPE: "sentencepiece",
    TOKENIZER_NAME: "conversational-english-12k-lc-12000"
}

#39_645_330
CONV_ENG_LC_12K_CONFIG_XS_300_6L_15H_690E = {
    CONFIG_NAME: "CONV_ENG_LC_12K_CONFIG_XS_300_6L_15H_690E",
    VOCABULARY_SIZE: 12000,
    CONTEXT_LENGTH: 300,
    EMBEDDING_DIMENSION: 690,
    N_HEADS: 15,
    N_LAYERS: 6,
    DROPOUT_EMBEDDING_RATE: 0,
    DROPOUT_ATTENTION_RATE: 0,
    DROPOUT_SHORTCUT_RATE: 0,
    QKV_BIAS: False,
    DEFAULT_DATA_TYPE: torch.bfloat16,
    TOKENIZER_TYPE: "sentencepiece",
    TOKENIZER_NAME: "conversational-english-12k-lc-12000"
}

#40_217_500
CONV_ENG_LC_12K_CONFIG_XS_350_14L_10H_500E = {
    CONFIG_NAME: "CONV_ENG_LC_12K_CONFIG_XS_350_14L_10H_500E",
    VOCABULARY_SIZE: 12000,
    CONTEXT_LENGTH: 350,
    EMBEDDING_DIMENSION: 500,
    N_HEADS: 10,
    N_LAYERS: 14,
    DROPOUT_EMBEDDING_RATE: 0,
    DROPOUT_ATTENTION_RATE: 0,
    DROPOUT_SHORTCUT_RATE: 0,
    QKV_BIAS: False,
    DEFAULT_DATA_TYPE: torch.bfloat16,
    TOKENIZER_TYPE: "sentencepiece",
    TOKENIZER_NAME: "conversational-english-12k-lc-12000"
}

################################
# CONV_ENG_LC_8K
################################

#30_079_200
CONV_ENG_LC_8K_CONFIG_XS_512_12L_12H_480E = {
    CONFIG_NAME: "CONV_ENG_LC_8K_CONFIG_XS_512_12L_12H_480E",
    VOCABULARY_SIZE: 8000,
    CONTEXT_LENGTH: 512,
    EMBEDDING_DIMENSION: 480,
    N_HEADS: 12,
    N_LAYERS: 12,
    DROPOUT_EMBEDDING_RATE: 0,
    DROPOUT_ATTENTION_RATE: 0,
    DROPOUT_SHORTCUT_RATE: 0,
    QKV_BIAS: False,
    DEFAULT_DATA_TYPE: torch.bfloat16,
    TOKENIZER_TYPE: "sentencepiece",
    TOKENIZER_NAME: "conversational-english-8k-lc-8000"
}

#19_002_720
CONV_ENG_LC_8K_CONFIG_XS_512_6L_12H_480E = {
    CONFIG_NAME: "CONV_ENG_LC_8K_CONFIG_XS_512_6L_12H_480E",
    VOCABULARY_SIZE: 8000,
    CONTEXT_LENGTH: 512,
    EMBEDDING_DIMENSION: 480,
    N_HEADS: 12,
    N_LAYERS: 6,
    DROPOUT_EMBEDDING_RATE: 0,
    DROPOUT_ATTENTION_RATE: 0,
    DROPOUT_SHORTCUT_RATE: 0,
    QKV_BIAS: False,
    DEFAULT_DATA_TYPE: torch.bfloat16,
    TOKENIZER_TYPE: "sentencepiece",
    TOKENIZER_NAME: "conversational-english-8k-lc-8000"
}

#18_924_960
CONV_ENG_LC_8K_CONFIG_XS_350_6L_12H_480E = {
    CONFIG_NAME: "CONV_ENG_LC_8K_CONFIG_XS_350_6L_12H_480E",
    VOCABULARY_SIZE: 8000,
    CONTEXT_LENGTH: 350,
    EMBEDDING_DIMENSION: 480,
    N_HEADS: 12,
    N_LAYERS: 6,
    DROPOUT_EMBEDDING_RATE: 0,
    DROPOUT_ATTENTION_RATE: 0,
    DROPOUT_SHORTCUT_RATE: 0,
    QKV_BIAS: False,
    DEFAULT_DATA_TYPE: torch.bfloat16,
    TOKENIZER_TYPE: "sentencepiece",
    TOKENIZER_NAME: "conversational-english-8k-lc-8000"
}

#14_256_360
CONV_ENG_LC_8K_CONFIG_XS_512_8L_12H_360E = {
    CONFIG_NAME: "CONV_ENG_LC_8K_CONFIG_XS_512_8L_12H_360E",
    VOCABULARY_SIZE: 8000,
    CONTEXT_LENGTH: 512,
    EMBEDDING_DIMENSION: 360,
    N_HEADS: 12,
    N_LAYERS: 8,
    DROPOUT_EMBEDDING_RATE: 0,
    DROPOUT_ATTENTION_RATE: 0,
    DROPOUT_SHORTCUT_RATE: 0,
    QKV_BIAS: False,
    DEFAULT_DATA_TYPE: torch.bfloat16,
    TOKENIZER_TYPE: "sentencepiece",
    TOKENIZER_NAME: "conversational-english-8k-lc-8000"
}

#12_875_856
CONV_ENG_LC_8K_CONFIG_XS_768_8L_12H_336E = {
    CONFIG_NAME: "CONV_ENG_LC_8K_CONFIG_XS_768_8L_12H_336E",
    VOCABULARY_SIZE: 8000,
    CONTEXT_LENGTH: 768,
    EMBEDDING_DIMENSION: 336,
    N_HEADS: 12,
    N_LAYERS: 8,
    DROPOUT_EMBEDDING_RATE: 0,
    DROPOUT_ATTENTION_RATE: 0,
    DROPOUT_SHORTCUT_RATE: 0,
    QKV_BIAS: False,
    DEFAULT_DATA_TYPE: torch.bfloat16,
    TOKENIZER_TYPE: "sentencepiece",
    TOKENIZER_NAME: "conversational-english-8k-lc-8000"
}

#8_673_696
CONV_ENG_LC_8K_CONFIG_XS_256_6L_12H_288E = {
    CONFIG_NAME: "CONV_ENG_LC_8K_CONFIG_XS_256_6L_12H_288E",
    VOCABULARY_SIZE: 8000,
    CONTEXT_LENGTH: 256,
    EMBEDDING_DIMENSION: 288,
    N_HEADS: 12,
    N_LAYERS: 6,
    DROPOUT_EMBEDDING_RATE: 0,
    DROPOUT_ATTENTION_RATE: 0,
    DROPOUT_SHORTCUT_RATE: 0,
    QKV_BIAS: False,
    DEFAULT_DATA_TYPE: torch.bfloat16,
    TOKENIZER_TYPE: "sentencepiece",
    TOKENIZER_NAME: "conversational-english-8k-lc-8000"
}

#1_056_540
CONV_ENG_LC_8K_CONFIG_XS_150_3L_6H_60E = {
    CONFIG_NAME: "CONV_ENG_LC_8K_CONFIG_XS_150_3L_6H_60E",
    VOCABULARY_SIZE: 8000,
    CONTEXT_LENGTH: 150,
    EMBEDDING_DIMENSION: 60,
    N_HEADS: 6,
    N_LAYERS: 3,
    DROPOUT_EMBEDDING_RATE: 0,
    DROPOUT_ATTENTION_RATE: 0,
    DROPOUT_SHORTCUT_RATE: 0,
    QKV_BIAS: False,
    DEFAULT_DATA_TYPE: torch.bfloat16,
    TOKENIZER_TYPE: "sentencepiece",
    TOKENIZER_NAME: "conversational-english-8k-lc-8000"
}

################################
# GPT
################################

GPT_CONFIG_SMALL = {
    CONFIG_NAME: "GPT_CONFIG_SMALL",
    VOCABULARY_SIZE: 50257,
    CONTEXT_LENGTH: 1024,
    EMBEDDING_DIMENSION: 768,
    N_HEADS: 12,
    N_LAYERS: 12,
    DROPOUT_EMBEDDING_RATE: 0,
    DROPOUT_ATTENTION_RATE: 0,
    DROPOUT_SHORTCUT_RATE: 0,
    QKV_BIAS: False,
    DEFAULT_DATA_TYPE: torch.float32,
    TOKENIZER_TYPE: "gpt2",
    TOKENIZER_NAME: None
}

GPT_CONFIG_124M = GPT_CONFIG_SMALL
GPT_CONFIG_124M[CONFIG_NAME] = "GPT_CONFIG_124M"

GPT_CONFIG_MEDIUM = {
    CONFIG_NAME: "GPT_CONFIG_MEDIUM",
    VOCABULARY_SIZE: 50257,
    CONTEXT_LENGTH: 1024,
    EMBEDDING_DIMENSION: 1024,
    N_HEADS: 16,
    N_LAYERS: 24,
    DROPOUT_EMBEDDING_RATE: 0,
    DROPOUT_ATTENTION_RATE: 0,
    DROPOUT_SHORTCUT_RATE: 0,
    QKV_BIAS: False,
    DEFAULT_DATA_TYPE: torch.float32,
    TOKENIZER_TYPE: "gpt2",
    TOKENIZER_NAME: None
}

GPT_CONFIG_LARGE = {
    CONFIG_NAME: "GPT_CONFIG_LARGE",
    VOCABULARY_SIZE: 50257,
    CONTEXT_LENGTH: 1024,
    EMBEDDING_DIMENSION: 1280,
    N_HEADS: 20,
    N_LAYERS: 36,
    DROPOUT_EMBEDDING_RATE: 0,
    DROPOUT_ATTENTION_RATE: 0,
    DROPOUT_SHORTCUT_RATE: 0,
    QKV_BIAS: False,
    DEFAULT_DATA_TYPE: torch.float32,
    TOKENIZER_TYPE: "gpt2",
    TOKENIZER_NAME: None
}


GPT_CONFIG_X_LARGE = {
    CONFIG_NAME: "GPT_CONFIG_X_LARGE",
    VOCABULARY_SIZE: 50257,
    CONTEXT_LENGTH: 1024,
    EMBEDDING_DIMENSION: 1600,
    N_HEADS: 25,
    N_LAYERS: 48,
    DROPOUT_EMBEDDING_RATE: 0,
    DROPOUT_ATTENTION_RATE: 0,
    DROPOUT_SHORTCUT_RATE: 0,
    QKV_BIAS: False,
    DEFAULT_DATA_TYPE: torch.float32,
    TOKENIZER_TYPE: "gpt2",
    TOKENIZER_NAME: None
}

modelConfigs = {
    # GPT
    "GPT_CONFIG_SMALL":GPT_CONFIG_SMALL,
    "GPT_CONFIG_124M":GPT_CONFIG_124M,
    "GPT_CONFIG_MEDIUM":GPT_CONFIG_MEDIUM,
    "GPT_CONFIG_LARGE":GPT_CONFIG_LARGE,
    "GPT_CONFIG_X_LARGE":GPT_CONFIG_X_LARGE,

    #CONV_ENG_8K_LC
    "CONV_ENG_LC_8K_CONFIG_XS_768_8L_12H_336E": CONV_ENG_LC_8K_CONFIG_XS_768_8L_12H_336E,
    "CONV_ENG_LC_8K_CONFIG_XS_256_6L_12H_288E": CONV_ENG_LC_8K_CONFIG_XS_256_6L_12H_288E,
    "CONV_ENG_LC_8K_CONFIG_XS_150_3L_6H_60E": CONV_ENG_LC_8K_CONFIG_XS_150_3L_6H_60E,
    "CONV_ENG_LC_8K_CONFIG_XS_350_6L_12H_480E": CONV_ENG_LC_8K_CONFIG_XS_350_6L_12H_480E,
    "CONV_ENG_LC_8K_CONFIG_XS_512_6L_12H_480E": CONV_ENG_LC_8K_CONFIG_XS_512_6L_12H_480E,
    "CONV_ENG_LC_8K_CONFIG_XS_512_8L_12H_360E": CONV_ENG_LC_8K_CONFIG_XS_512_8L_12H_360E,
    "CONV_ENG_LC_8K_CONFIG_XS_512_12L_12H_480E": CONV_ENG_LC_8K_CONFIG_XS_512_12L_12H_480E,

    #CONV_ENG_12K_LC
    "CONV_ENG_LC_12K_CONFIG_XS_512_6L_12H_480E": CONV_ENG_LC_12K_CONFIG_XS_512_6L_12H_480E,
    "CONV_ENG_LC_12K_CONFIG_XS_300_12L_15H_345E": CONV_ENG_LC_12K_CONFIG_XS_300_12L_15H_345E,
    "CONV_ENG_LC_12K_CONFIG_XS_300_24L_15H_345E": CONV_ENG_LC_12K_CONFIG_XS_300_24L_15H_345E,    
    "CONV_ENG_LC_12K_CONFIG_XS_300_6L_15H_690E": CONV_ENG_LC_12K_CONFIG_XS_300_6L_15H_690E,
    "CONV_ENG_LC_12K_CONFIG_XS_350_14L_10H_500E": CONV_ENG_LC_12K_CONFIG_XS_350_14L_10H_500E, 

    #CONV_ENG_16K_LC
    "CONV_ENG_LC_16K_CONFIG_XS_512_6L_12H_480E": CONV_ENG_LC_16K_CONFIG_XS_512_6L_12H_480E
}

def getDataTypeFromConfig(config): 
    # https://medium.com/data-science/pytorch-native-fp8-fedc06f1c9f7
    dt = torch.float32
    cfgDt = config[DEFAULT_DATA_TYPE]
    if cfgDt == 'bfloat16':
        dt = torch.bfloat16
    elif cfgDt == 'float16':
        dt = torch.float16
    elif cfgDt == 'float8_e4m3fn':
        dt = torch.float8_e4m3fn
    elif cfgDt == 'float8_e4m3fnuz':
        dt = torch.float8_e4m3fnuz
    elif cfgDt == 'float8_e5m2':
        dt = torch.float8_e5m2
    elif cfgDt == 'float8_e5m2fnuz':
        dt = torch.float8_e5m2fnuz
    elif cfgDt == 'float8_e8m0fnu':
        dt = torch.float8_e8m0fnu   

    return dt
