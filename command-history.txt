
python3 PreProcessDataFiles.py --inputData="./input-data/english-subtitles-cleaned/english-subtitles-cleaned-0[0-2][0-9].txt" --outputFileName="english-subtitles-cleaned-cee-000-029-12k" --isTokenized --forceLowerCase --newOutputFile --outputBatchSizeMb=150 --vocabulary="conversational-emotion-english-12k-lc-12000" --tokenizer=sentencepiece --newOutputFile ;
python3 PreProcessDataFiles.py --inputData="./input-data/english-subtitles-cleaned/english-subtitles-cleaned-0[3-6][0-9].txt" --outputFileName="english-subtitles-cleaned-cee-030-069-12k" --isTokenized --forceLowerCase --newOutputFile --outputBatchSizeMb=150 --vocabulary="conversational-emotion-english-12k-lc-12000" --tokenizer=sentencepiece --newOutputFile ;
python3 PreProcessDataFiles.py --inputData="./input-data/english-subtitles-cleaned/english-subtitles-cleaned-0[6-9][9-9].txt" --outputFileName="english-subtitles-cleaned-cee-069-099-12k" --isTokenized --forceLowerCase --newOutputFile --outputBatchSizeMb=150 --vocabulary="conversational-emotion-english-12k-lc-12000" --tokenizer=sentencepiece --newOutputFile ;
python3 PreProcessDataFiles.py --inputData="./input-data/english-subtitles-cleaned/english-subtitles-cleaned-1[0-9][0-9].txt" --outputFileName="english-subtitles-cleaned-cee-100-130-12k" --isTokenized --forceLowerCase --newOutputFile --outputBatchSizeMb=150 --vocabulary="conversational-emotion-english-12k-lc-12000" --tokenizer=sentencepiece --newOutputFile


python3 PreProcessDataFiles.py --inputData="./input-data/english-subtitles-cleaned/english-subtitles-cleaned-0[0-2][0-9].txt" --outputFileName="english-subtitles-cleaned-cee-000-029-16k" --isTokenized --forceLowerCase --newOutputFile --outputBatchSizeMb=150 --vocabulary="conversational-emotion-english-16k-lc-16000" --tokenizer=sentencepiece --newOutputFile ;
python3 PreProcessDataFiles.py --inputData="./input-data/english-subtitles-cleaned/english-subtitles-cleaned-0[3-6][0-9].txt" --outputFileName="english-subtitles-cleaned-cee-030-069-16k" --isTokenized --forceLowerCase --newOutputFile --outputBatchSizeMb=150 --vocabulary="conversational-emotion-english-16k-lc-16000" --tokenizer=sentencepiece --newOutputFile ;
python3 PreProcessDataFiles.py --inputData="./input-data/english-subtitles-cleaned/english-subtitles-cleaned-0[6-9][9-9].txt" --outputFileName="english-subtitles-cleaned-cee-069-099-16k" --isTokenized --forceLowerCase --newOutputFile --outputBatchSizeMb=150 --vocabulary="conversational-emotion-english-16k-lc-16000" --tokenizer=sentencepiece --newOutputFile ;
python3 PreProcessDataFiles.py --inputData="./input-data/english-subtitles-cleaned/english-subtitles-cleaned-1[0-9][0-9].txt" --outputFileName="english-subtitles-cleaned-cee-100-130-16k" --isTokenized --forceLowerCase --newOutputFile --outputBatchSizeMb=150 --vocabulary="conversational-emotion-english-16k-lc-16000" --tokenizer=sentencepiece --newOutputFile


python3 PreProcessDataFiles.py --inputData="./input-data/english-subtitles-cleaned/english-subtitles-cleaned-0[0-2][0-9].txt" --outputFileName="english-subtitles-cleaned-cee-l-000-029-16k" --isTokenized --forceLowerCase --newOutputFile --outputBatchSizeMb=500 --vocabulary="conversational-emotion-english-16k-lc-16000" --tokenizer=sentencepiece --newOutputFile ;
python3 PreProcessDataFiles.py --inputData="./input-data/english-subtitles-cleaned/english-subtitles-cleaned-0[3-6][0-9].txt" --outputFileName="english-subtitles-cleaned-cee-l-030-069-16k" --isTokenized --forceLowerCase --newOutputFile --outputBatchSizeMb=500 --vocabulary="conversational-emotion-english-16k-lc-16000" --tokenizer=sentencepiece --newOutputFile ;
python3 PreProcessDataFiles.py --inputData="./input-data/english-subtitles-cleaned/english-subtitles-cleaned-0[6-9][9-9].txt" --outputFileName="english-subtitles-cleaned-cee-l-069-099-16k" --isTokenized --forceLowerCase --newOutputFile --outputBatchSizeMb=500 --vocabulary="conversational-emotion-english-16k-lc-16000" --tokenizer=sentencepiece --newOutputFile ;
python3 PreProcessDataFiles.py --inputData="./input-data/english-subtitles-cleaned/english-subtitles-cleaned-1[0-9][0-9].txt" --outputFileName="english-subtitles-cleaned-cee-l-100-130-16k" --isTokenized --forceLowerCase --newOutputFile --outputBatchSizeMb=500 --vocabulary="conversational-emotion-english-16k-lc-16000" --tokenizer=sentencepiece --newOutputFile



python3 PreProcessDataFiles.py --inputData="./input-data/english-subtitles-cleaned/english-subtitles-cleaned-*.txt" --outputFileName="english-subtitles-cleaned-large-12k" --isTokenized --forceLowerCase --newOutputFile --outputBatchSizeMb=600 --vocabulary="conversational-english-12k-lc-12000" --tokenizer=sentencepiece --newOutputFile ;

------ short conv

-- wiki data conversations
python3 OllamaGenerateTestDataFromFiles.py --printInterval=10 --startFromFileIndex=3620 --outputFileName=synthetic-factual-simple-wiki-conversations

--data

--- emotions
echo '--280m casual' ;
python3 OllamaGenerateTestData.py --model="llama3.2:3b" --printInterval=10 --prompt="generate a casual conversation between 300 and 1200 words with sentences that are no larger than 50 words, only output the conversations and no other text, put the participants names between brackets [$name], do not use names in the conversation" --outputFileName="synthetic-emotion-short-casual-conversations" --generationSizeMb=25;
echo '--70m romantic';
python3 OllamaGenerateTestData.py --model="llama3.2:3b" --printInterval=10 --prompt="generate a romantic, cozy or flirty conversation between 300 and 1000 words with sentences that are no larger than 50 words, only output the conversations and no other text, put the participants names between brackets [$name], do not use names in the conversation" --outputFileName="synthetic-emotion-short-romantic-conversations" --generationSizeMb=25;
echo '--25m upbeat';
python3 OllamaGenerateTestData.py --model="llama3.2:3b" --printInterval=10 --prompt="generate an upbeat conversation between 300 and 1200 words with sentences that are no larger than 50 words, only output the conversations and no other text, put the participants names between brackets [$name], do not use names in the conversation" --outputFileName="synthetic-emotion-short-upbeat-conversations" --generationSizeMb=25;
echo '--7m annoyed contempt';
python3 OllamaGenerateTestData.py --model="llama3.2:3b" --printInterval=10 --prompt="generate an annoyed or contemptfull conversation between 300 and 1200 words with sentences that are no larger than 50 words, only output the conversations and no other text, put the participants names between brackets [$name], do not use names in the conversation" --outputFileName="synthetic-emotion-short-annoyed-conversations" --generationSizeMb=25;
echo '--10m suprised' ;
python3 OllamaGenerateTestData.py --model="llama3.2:3b" --printInterval=10 --prompt="generate a conversation where you are suprised by an event between 300 and 1200 words with sentences that are no larger than 50 words, only output the conversations and no other text, put the participants names between brackets [$name], do not use names in the conversation" --outputFileName="synthetic-emotion-short-suprised-conversations" --generationSizeMb=10;
echo '--6m interested' ;
python3 OllamaGenerateTestData.py --model="llama3.2:3b" --printInterval=10 --prompt="generate a conversation asking about personal interests between 300 and 1200 words with sentences that are no larger than 50 words, only output the conversations and no other text, put the participants names between brackets [$name], do not use names in the conversation" --outputFileName="synthetic-emotion-short-interested-conversations" --generationSizeMb=10 ;
echo '--15m joy' ;
python3 OllamaGenerateTestData.py --model="llama3.2:3b" --printInterval=10 --prompt="generate a joyous conversation between 300 and 1200 words with sentences that are no larger than 50 words, only output the conversations and no other text, put the participants names between brackets [$name], do not use names in the conversation" --outputFileName="synthetic-emotion-short-joyous-conversations" --generationSizeMb=10 ;
echo '--57m sad' ;
python3 OllamaGenerateTestData.py --model="llama3.2:3b" --printInterval=10 --prompt="generate a sad conversation between 300 and 1200 words with sentences that are no larger than 50 words, only output the conversations and no other text, put the participants names between brackets [$name], do not use names in the conversation" --outputFileName="synthetic-emotion-short-sad-conversations" --generationSizeMb=40 ;
echo '--0m angry disgusted' ;
python3 OllamaGenerateTestData.py --model="llama3.2:3b" --printInterval=10 --prompt="generate an angry or disgusted conversation between 300 and 1200 words with sentences that are no larger than 50 words, only output the conversations and no other text, put the participants names between brackets [$name], do not use names in the conversation" --outputFileName="synthetic-emotion-short-angry-disgusted-conversations" --generationSizeMb=10 ;
echo '--0m shamefull' ;
python3 OllamaGenerateTestData.py --model="llama3.2:3b" --printInterval=10 --prompt="generate an shamefull or guilty conversation between 300 and 1200 words with sentences that are no larger than 50 words, only output the conversations and no other text, put the participants names between brackets [$name], do not use names in the conversation" --outputFileName="synthetic-emotion-short-shamefull-conversations" --generationSizeMb=10 ;
echo '--0m fearfull' ;
python3 OllamaGenerateTestData.py --model="llama3.2:3b" --printInterval=10 --prompt="generate an fearfull conversation between 300 and 1200 words with sentences that are no larger than 50 words, only output the conversations and no other text, put the participants names between brackets [$name], do not use names in the conversation" --outputFileName="synthetic-emotion-short-fearfull-conversations" --generationSizeMb=10 ;
echo '--79m shy' ;
python3 OllamaGenerateTestData.py --model="llama3.2:3b" --printInterval=10 --prompt="generate an shy conversation between 300 and 1200 words with sentences that are no larger than 50 words, only output the conversations and no other text, put the participants names between brackets [$name], do not use names in the conversation" --outputFileName="synthetic-emotion-short-shy-conversations" --generationSizeMb=30 ;


----Interest




python3 OllamaGenerateTestData.py --model="llama3.2:3b" --printInterval=10 --prompt="generate an general knowledge conversation between 300 and 1000 words with sentences that are no larger than 50 words, only output the conversations and no other text, put the participants names between brackets [$name], do not use names in the conversation" --outputFileName="synthetic-factual-short-conversations" --numberOfGenerations=100000

python3 OllamaGenerateTestData.py --model="llama3.2:3b" --printInterval=10 --prompt="generate an general knowledge conversation between 300 and 1000 words  on any of the the topics of geography, culture, society or relations with sentences that are no larger than 50 words, only output the conversations and no other text, put the participants names between brackets [$name], do not use names in the conversation" --outputFileName="synthetic-factual-short-conversations-js" --numberOfGenerations=100000

--tokenizer
python3 PreProcessTokenizer.py --inputData="./input-data/synthetic-**/**.txt" --vocabSize=8000 --vocabularyName="conversational-english-8k-lc" --forceLowerCase --newTrainingFile ;  
python3 PreProcessTokenizer.py --inputData="./input-data/synthetic-emotion-*/**.txt" --vocabSize=8000 --vocabularyName="conversational-emotion-english-8k-lc" --forceLowerCase --newTrainingFile  

python3 PreProcessTokenizer.py --inputData="./input-data/synthetic-**/**.txt" --vocabSize=12000 --vocabularyName="conversational-english-12k-lc" --forceLowerCase --newTrainingFile ;  
python3 PreProcessTokenizer.py --inputData="./input-data/synthetic-emotion-*/**.txt" --vocabSize=12000 --vocabularyName="conversational-emotion-english-12k-lc" --forceLowerCase --newTrainingFile  

python3 PreProcessTokenizer.py --inputData="./input-data/synthetic-**/**.txt" --vocabSize=16000 --vocabularyName="conversational-english-16k-lc" --forceLowerCase --newTrainingFile  
python3 PreProcessTokenizer.py --inputData="./input-data/synthetic-emotion-*/**.txt" --vocabSize=16000 --vocabularyName="conversational-emotion-english-16k-lc" --forceLowerCase --newTrainingFile  

--preprocess PreProcessDataFiles
python3 PreProcessDataFiles.py --inputData="./input-data/synthetic-casual-conversations/**.txt" --outputFileName="synthetic-casual-conversations-8k" --isTokenized --forceLowerCase --newOutputFile --outputBatchSizeMb=150 --vocabulary="conversational-emotion-english-8k-lc-8000" --tokenizer=sentencepiece --newOutputFile ;
python3 PreProcessDataFiles.py --inputData="./input-data/synthetic-short-**/**.txt" --outputFileName="synthetic-short-conversations-8k" --isTokenized --forceLowerCase --newOutputFile --outputBatchSizeMb=150 --vocabulary="conversational-emotion-english-8k-lc-8000" --tokenizer=sentencepiece --newOutputFile ;
python3 PreProcessDataFiles.py --inputData="./input-data/synthetic-**/**.txt" --outputFileName="synthetic-conversations-8k" --isTokenized --forceLowerCase --newOutputFile --outputBatchSizeMb=600 --vocabulary="conversational-emotion-english-8k-lc-8000" --tokenizer=sentencepiece --newOutputFile ;

;

python3 PreProcessDataFiles.py --inputData="./input-data/synthetic-casual-conversations/**.txt" --outputFileName="synthetic-casual-conversations-12k" --isTokenized --forceLowerCase --newOutputFile --outputBatchSizeMb=150 --vocabulary="conversational-emotion-english-12k-lc-12000" --tokenizer=sentencepiece --newOutputFile ;
python3 PreProcessDataFiles.py --inputData="./input-data/synthetic-short-**/**.txt" --outputFileName="synthetic-short-conversations-12k" --isTokenized --forceLowerCase --newOutputFile --outputBatchSizeMb=150 --vocabulary="conversational-emotion-english-12k-lc-12000" --tokenizer=sentencepiece --newOutputFile ;
python3 PreProcessDataFiles.py --inputData="./input-data/synthetic-**/**.txt" --outputFileName="synthetic-conversations-12k" --isTokenized --forceLowerCase --newOutputFile --outputBatchSizeMb=500 --vocabulary="conversational-emotion-english-12k-lc-12000" --tokenizer=sentencepiece --newOutputFile ;
python3 PreProcessDataFiles.py --inputData="./input-data/synthetic-emotion-*/**.txt" --outputFileName="synthetic-conversations-emotion-12k" --isTokenized --forceLowerCase --newOutputFile --outputBatchSizeMb=600 --vocabulary="conversational-emotion-english-12k-lc-12000" --tokenizer=sentencepiece --newOutputFile ;

;

python3 PreProcessDataFiles.py --inputData="./input-data/synthetic-casual-conversations/**.txt" --outputFileName="synthetic-casual-conversations-16k" --isTokenized --forceLowerCase --newOutputFile --outputBatchSizeMb=150 --vocabulary="conversational-emotion-english-16k-lc-16000" --tokenizer=sentencepiece --newOutputFile ;
python3 PreProcessDataFiles.py --inputData="./input-data/synthetic-short-**/**.txt" --outputFileName="synthetic-short-conversations-16k" --isTokenized --forceLowerCase --newOutputFile --outputBatchSizeMb=150 --vocabulary="conversational-emotion-english-16k-lc-16000" --tokenizer=sentencepiece --newOutputFile ;
python3 PreProcessDataFiles.py --inputData="./input-data/synthetic-**/**.txt" --outputFileName="synthetic-conversations-16k" --isTokenized --forceLowerCase --newOutputFile --outputBatchSizeMb=500 --vocabulary="conversational-emotion-english-16k-lc-16000" --tokenizer=sentencepiece --newOutputFile ;
python3 PreProcessDataFiles.py --inputData="./input-data/synthetic-emotion-*/**.txt" --outputFileName="synthetic-conversations-emotion-16k" --isTokenized --forceLowerCase --newOutputFile --outputBatchSizeMb=600 --vocabulary="conversational-emotion-english-16k-lc-16000" --tokenizer=sentencepiece --newOutputFile ;

python3 PreProcessDataFiles.py --inputData="./input-data/synthetic-*casual*/**.txt" --outputFileName="synthetic-casual-conversations-emotion-16k" --isTokenized --forceLowerCase --newOutputFile --outputBatchSizeMb=600 --vocabulary="conversational-emotion-english-16k-lc-16000" --tokenizer=sentencepiece --newOutputFile ;


--train
--8k
python3 TrainModel.py --model="english-conversations-lc-8k-30_0m" --inputData="processed-data/synthetic-casual-conversations-8k/**.bin" --device="mps" --startContext="hey how are you?[eos]" --warmupSteps=300 --evaluationStepFrequency=100 --checkpointStepStorageFrequency=1000 --batchSize=25  --numberOfEpochs=8 --peakLearningRate=0.003 --minimalLearningRate=0.0005 --weightDecay=0.0005 --config="CONV_ENG_LC_8K_CONFIG_XS_512_12L_12H_480E" --newModel 
;
python3 TrainModel.py --model="english-conversations-lc-8k-30_0m-1" --inputData="processed-data/synthetic-short-conversations-8k/**.bin" --device="mps" --startContext="hey how are you?[eos]" --warmupSteps=300 --evaluationStepFrequency=100 --checkpointStepStorageFrequency=1000 --batchSize=25  --numberOfEpochs=8 --peakLearningRate=0.001 --minimalLearningRate=0.0001 --weightDecay=0.0005 --shuffleBatches --config="CONV_ENG_LC_8K_CONFIG_XS_512_12L_12H_480E"  --copyModel
;

--8k 8_
python3 TrainModel.py --model="english-conversations-lc-8k-8_4m" --inputData="processed-data/synthetic-short-conversations-8k/**.bin" --device="mps" --startContext="hey how are you?[eos]" --warmupSteps=300 --evaluationStepFrequency=100 --checkpointStepStorageFrequency=1000 --batchSize=100  --numberOfEpochs=4 --peakLearningRate=0.001 --minimalLearningRate=0.0001 --weightDecay=0.0005 --shuffleBatches --config="CONV_ENG_LC_8K_CONFIG_XS_300_5L_5H_300E"  --newModel


--12k - 19_8m
python3 TrainModel.py --model="english-conversations-lc-12k-19_8m" --inputData="processed-data/synthetic-casual-conversations-12k/**.bin" --device="mps" --startContext="hey how are you?[eos]" --warmupSteps=100 --evaluationStepFrequency=100 --checkpointStepStorageFrequency=1000 --batchSize=25  --numberOfEpochs=4 --peakLearningRate=0.002 --minimalLearningRate=0.0010 --weightDecay=0.0005 --config="CONV_ENG_LC_12K_CONFIG_XS_300_12L_15H_345E" --newModel
;
python3 TrainModel.py --model="english-conversations-lc-12k-19_8m" --inputData="processed-data/synthetic-short-conversations-12k/**.bin" --device="mps" --startContext="hey how are you?[eos]" --warmupSteps=300 --evaluationStepFrequency=100 --checkpointStepStorageFrequency=1000 --batchSize=25  --numberOfEpochs=4 --peakLearningRate=0.0012 --minimalLearningRate=0.0001 --weightDecay=0.0005 --shuffleBatches --config="CONV_ENG_LC_12K_CONFIG_XS_300_12L_15H_345E" --copyModel 

--12k - 35_4m
python3 TrainModel.py --model="english-conversations-lc-12k-35_4m" --inputData="processed-data/synthetic-conversations-12k/**.bin" --shuffleBatches --device="mps" --startContext="hey how are you?[eos]" --warmupSteps=100 --evaluationStepFrequency=100 --checkpointStepStorageFrequency=1000 --batchSize=25  --numberOfEpochs=8 --peakLearningRate=0.002 --minimalLearningRate=0.0001 --weightDecay=0.0005 --config="CONV_ENG_LC_12K_CONFIG_XS_400_24L_10H_400E" --newModel

--12k - 18_3m
python3 TrainModel.py --model="english-conversations-lc-12k-18_3m" --inputData="processed-data/synthetic-conversations-12k/**.bin" --shuffleBatches --device="mps" --startContext="hey how are you?[eos]" --warmupSteps=100 --evaluationStepFrequency=100 --checkpointStepStorageFrequency=1000 --batchSize=50  --numberOfEpochs=8 --peakLearningRate=0.003 --minimalLearningRate=0.0001 --weightDecay=0.0005 --config="CONV_ENG_LC_12K_CONFIG_XS_300_10L_10H_350E" --newModel

--12k - 23_9m
python3 TrainModel.py --model="english-conversations-lc-12k-23_9m" --inputData="processed-data/synthetic-conversations-12k/**.bin" --shuffleBatches --device="mps" --startContext="hey how are you?[eos]" --warmupSteps=100 --evaluationStepFrequency=100 --checkpointStepStorageFrequency=1000 --batchSize=50  --numberOfEpochs=9 --peakLearningRate=0.004 --minimalLearningRate=0.0001 --weightDecay=0.0005 --config="CONV_ENG_LC_12K_CONFIG_XS_400_8L_10H_450E" --newModel


--12k - 39_6m

python3 TrainModel.py --model="english-conversations-lc-12k-39_6m" --inputData="processed-data/english-subtitles-cleaned-000-029-12k/**.bin" --device="mps" --startContext="hey how are you?[eos]" --warmupSteps=100 --evaluationStepFrequency=100 --checkpointStepStorageFrequency=1000 --batchSize=25  --numberOfEpochs=1 --peakLearningRate=0.0005 --minimalLearningRate=0.0001 --weightDecay=0.0005 --config="CONV_ENG_LC_12K_CONFIG_XS_300_6L_15H_690E" --newModel
;
python3 TrainModel.py --model="english-conversations-lc-12k-39_6m-1" --inputData="processed-data/synthetic-casual-conversations-12k/**.bin" --device="mps" --startContext="hey how are you?[eos]" --warmupSteps=100 --evaluationStepFrequency=100 --checkpointStepStorageFrequency=1000 --batchSize=25  --numberOfEpochs=8 --peakLearningRate=0.0005 --minimalLearningRate=0.00001 --weightDecay=0.0005 --config="CONV_ENG_LC_12K_CONFIG_XS_300_6L_15H_690E" --copyModel
;
python3 TrainModel.py --model="english-conversations-lc-12k-39_6m-1-1" --inputData="processed-data/synthetic-short-conversations-12k/**.bin" --device="mps" --startContext="hey how are you?[eos]" --warmupSteps=300 --evaluationStepFrequency=100 --checkpointStepStorageFrequency=1000 --batchSize=25  --numberOfEpochs=12 --peakLearningRate=0.0003 --minimalLearningRate=0.00001 --weightDecay=0.0005 --shuffleBatches --config="CONV_ENG_LC_12K_CONFIG_XS_300_6L_15H_690E" --copyModel 

--12k - 40_2m

python3 TrainModel.py --model="english-conversations-lc-12k-40_2m" --inputData="processed-data/english-subtitles-cleaned-000-029-12k/**.bin" --device="mps" --startContext="hey how are you?[eos]" --warmupSteps=100 --evaluationStepFrequency=100 --checkpointStepStorageFrequency=1000 --batchSize=25  --numberOfEpochs=1 --peakLearningRate=0.0005 --minimalLearningRate=0.0002 --weightDecay=0.0005 --config="CONV_ENG_LC_12K_CONFIG_XS_350_14L_10H_500E" --newModel
;
python3 TrainModel.py --model="english-conversations-lc-12k-40_2m-1" --inputData="processed-data/synthetic-conversations-12k/**.bin" --device="mps" --startContext="hey how are you?[eos]" --warmupSteps=100 --evaluationStepFrequency=100 --checkpointStepStorageFrequency=1000 --batchSize=25  --numberOfEpochs=16 --peakLearningRate=0.0005 --minimalLearningRate=0.000001 --weightDecay=0.0005 --config="CONV_ENG_LC_12K_CONFIG_XS_350_14L_10H_500E" --copyModel

python3 TrainModel.py --model="english-conversations-lc-lambda-12k-40_2m-1" --inputData="processed-data/synthetic-conversations-12k/**.bin" --device="mps" --startContext="hey how are you?[eos]" --warmupSteps=100 --evaluationStepFrequency=100 --checkpointStepStorageFrequency=1000 --batchSize=25  --numberOfEpochs=3 --peakLearningRate=0.00001 --minimalLearningRate=0.00001 --weightDecay=0.0005 --config="CONV_ENG_LC_12K_CONFIG_XS_350_14L_10H_500E" --copyModel


--16k

--one shot, worked well
python3 TrainModel.py --model="english-conversations-v2-lc-16k-27_5m" --inputData="processed-data/synthetic-conversations-emotion-16k/**.bin" --shuffleBatches --device="mps" --startContext="hey how are you?[eos]" --warmupSteps=100 --evaluationStepFrequency=100 --checkpointStepStorageFrequency=1000 --batchSize=50  --numberOfEpochs=9 --peakLearningRate=0.004 --minimalLearningRate=0.0005 --weightDecay=0.0005 --config="CONV_ENG_LC_16K_CONFIG_XS_400_8L_10H_450E" --newModel

--one shot, worked well
python3 TrainModel.py --model="english-conversations-lc-16k-30_8m" --inputData="processed-data/synthetic-conversations-emotion-16k/**.bin" --shuffleBatches --device="mps" --startContext="hey how are you?[eos]" --warmupSteps=100 --evaluationStepFrequency=100 --checkpointStepStorageFrequency=1000 --batchSize=50  --numberOfEpochs=9 --peakLearningRate=0.004 --minimalLearningRate=0.0005 --weightDecay=0.0005 --config="CONV_ENG_LC_16K_CONFIG_XS_400_10L_10H_450E" --newModel


python3 TrainModel.py --model="english-conversations-lc-16k-33_3m" --inputData="processed-data/synthetic-casual-conversations-emotion-16k/**.bin" --shuffleBatches --device="mps" --startContext="hey how are you?[eos]" --warmupSteps=100 --evaluationStepFrequency=100 --checkpointStepStorageFrequency=1000 --batchSize=50  --numberOfEpochs=9 --peakLearningRate=0.003 --minimalLearningRate=0.0001 --weightDecay=0.0005 --config="CONV_ENG_LC_16K_CONFIG_XS_400_8L_8H_512E" --newModel


python3 TrainModel.py --model="english-conversations-full-lc-16k-33_3m" --inputData="processed-data/synthetic-conversations-emotion-16k/**.bin" --device="mps" --startContext="hey how are you?[eos]" --warmupSteps=100 --evaluationStepFrequency=100 --checkpointStepStorageFrequency=1000 --batchSize=50  --numberOfEpochs=8 --peakLearningRate=0.004 --minimalLearningRate=0.002 --weightDecay=0.002 --config="CONV_ENG_LC_16K_CONFIG_XS_400_8L_8H_512E" --newModel;
python3 TrainModel.py --model="english-conversations-full-lc-16k-33_3m" --inputData="processed-data/synthetic-conversations-emotion-16k/**.bin" --device="mps" --startContext="hey how are you?[eos]" --warmupSteps=100 --evaluationStepFrequency=100 --checkpointStepStorageFrequency=1000 --batchSize=50  --numberOfEpochs=5 --peakLearningRate=0.0025 --minimalLearningRate=0.001 --weightDecay=0.001 --config="CONV_ENG_LC_16K_CONFIG_XS_400_8L_8H_512E" ;
python3 TrainModel.py --model="english-conversations-full-lc-16k-33_3m" --inputData="processed-data/synthetic-conversations-emotion-16k/**.bin" --device="mps" --startContext="hey how are you?[eos]" --warmupSteps=100 --evaluationStepFrequency=100 --checkpointStepStorageFrequency=1000 --batchSize=50  --numberOfEpochs=5 --peakLearningRate=0.0015 --minimalLearningRate=0.0001 --weightDecay=0.0001 --config="CONV_ENG_LC_16K_CONFIG_XS_400_8L_8H_512E" ;



python3 TrainModel.py --model="english-conversations-full-lc-16k-33_4m" --inputData="processed-data/synthetic-conversations-emotion-16k/**.bin" --device="mps" --startContext="hey how are you?[eos]" --warmupSteps=200 --evaluationStepFrequency=200 --checkpointStepStorageFrequency=1000 --batchSize=40  --numberOfEpochs=8 --peakLearningRate=0.004 --minimalLearningRate=0.002 --weightDecay=0.002 --config="CONV_ENG_LC_16K_CONFIG_XS_500_8L_16H_512E" --newModel;
python3 TrainModel.py --model="english-conversations-full-lc-16k-33_4m" --inputData="processed-data/synthetic-conversations-emotion-16k/**.bin" --device="mps" --startContext="hey how are you?[eos]" --warmupSteps=200 --evaluationStepFrequency=200 --checkpointStepStorageFrequency=1000 --batchSize=40  --numberOfEpochs=5 --peakLearningRate=0.0025 --minimalLearningRate=0.001 --weightDecay=0.001 --config="CONV_ENG_LC_16K_CONFIG_XS_500_8L_16H_512E" ;
python3 TrainModel.py --model="english-conversations-full-lc-16k-33_4m" --inputData="processed-data/synthetic-conversations-emotion-16k/**.bin" --device="mps" --startContext="hey how are you?[eos]" --warmupSteps=200 --evaluationStepFrequency=200 --checkpointStepStorageFrequency=1000 --batchSize=40  --numberOfEpochs=5 --peakLearningRate=0.0015 --minimalLearningRate=0.0001 --weightDecay=0.0001 --config="CONV_ENG_LC_16K_CONFIG_XS_500_8L_16H_512E" ;
