import torch 

CONFIG_NAME = "ConfigName"
VOCABULARY_SIZE = "VocabularySize"

CONTEXT_LENGTH = "ContextLength"
EMBEDDING_DIMENSION = "EmbeddingDimension"
N_HEADS = "NumberOfHeads"
N_LAYERS = "NumberOfLayers"
DROPOUT_EMBEDDING_RATE = "EmbeddingDropoutRate"
DROPOUT_ATTENTION_RATE = "AttentionDropoutRate"
DROPOUT_SHORTCUT_RATE = "TransformerDropoutRate"
QKV_BIAS = "QKVBias"
DEFAULT_DATA_TYPE = "DefaultDataType"

TOKENIZER_TYPE = "TokenizerType"
TOKENIZER_NAME = "TokenizerName"


################################
# CONV_ENG_LC_16K
################################


#71_884_150
CONV_ENG_LC_16K_CONFIG_XS_500_15L_10H_750E = {
    CONFIG_NAME: "CONV_ENG_LC_16K_CONFIG_XS_500_15L_10H_750E",
    VOCABULARY_SIZE: 16000,
    CONTEXT_LENGTH: 500,
    EMBEDDING_DIMENSION: 650,
    N_HEADS: 10,
    N_LAYERS: 15,
    DROPOUT_EMBEDDING_RATE: 0,
    DROPOUT_ATTENTION_RATE: 0,
    DROPOUT_SHORTCUT_RATE: 0,
    QKV_BIAS: False,
    DEFAULT_DATA_TYPE: torch.bfloat16,
    TOKENIZER_TYPE: "sentencepiece",
    TOKENIZER_NAME: "conversational-emotion-english-16k-lc-16000"
}

#66_341_550
CONV_ENG_LC_16K_CONFIG_XS_500_20L_10H_550E = {
    CONFIG_NAME: "CONV_ENG_LC_16K_CONFIG_XS_500_20L_10H_550E",
    VOCABULARY_SIZE: 16000,
    CONTEXT_LENGTH: 500,
    EMBEDDING_DIMENSION: 550,
    N_HEADS: 10,
    N_LAYERS: 20,
    DROPOUT_EMBEDDING_RATE: 0,
    DROPOUT_ATTENTION_RATE: 0,
    DROPOUT_SHORTCUT_RATE: 0,
    QKV_BIAS: False,
    DEFAULT_DATA_TYPE: torch.bfloat16,
    TOKENIZER_TYPE: "sentencepiece",
    TOKENIZER_NAME: "conversational-emotion-english-16k-lc-16000"
}

#33_442_304
CONV_ENG_LC_16K_CONFIG_XS_500_8L_16H_512E = {
    CONFIG_NAME: "CONV_ENG_LC_16K_CONFIG_XS_500_8L_16H_512E",
    VOCABULARY_SIZE: 16000,
    CONTEXT_LENGTH: 500,
    EMBEDDING_DIMENSION: 512, #32
    N_HEADS: 16,
    N_LAYERS: 8,
    DROPOUT_EMBEDDING_RATE: 0.0,
    DROPOUT_ATTENTION_RATE: 0.0,
    DROPOUT_SHORTCUT_RATE: 0.0,
    QKV_BIAS: False,
    DEFAULT_DATA_TYPE: torch.bfloat16,
    TOKENIZER_TYPE: "sentencepiece",
    TOKENIZER_NAME: "conversational-emotion-english-16k-lc-16000"
}


#20_940_032
CONV_ENG_LC_16K_CONFIG_XS_500_24L_8H_256E = {
    CONFIG_NAME: "CONV_ENG_LC_16K_CONFIG_XS_500_24L_8H_256E",
    VOCABULARY_SIZE: 16000,
    CONTEXT_LENGTH: 500,
    EMBEDDING_DIMENSION: 256, #32
    N_HEADS: 8,
    N_LAYERS: 24,
    DROPOUT_EMBEDDING_RATE: 0.0,
    DROPOUT_ATTENTION_RATE: 0.0,
    DROPOUT_SHORTCUT_RATE: 0.0,
    QKV_BIAS: False,
    DEFAULT_DATA_TYPE: torch.bfloat16,
    TOKENIZER_TYPE: "sentencepiece",
    TOKENIZER_NAME: "conversational-emotion-english-16k-lc-16000"
}

#33_391_104
CONV_ENG_LC_16K_CONFIG_XS_400_8L_8H_512E = {
    CONFIG_NAME: "CONV_ENG_LC_16K_CONFIG_XS_400_8L_8H_512E",
    VOCABULARY_SIZE: 16000,
    CONTEXT_LENGTH: 400,
    EMBEDDING_DIMENSION: 512, #64
    N_HEADS: 8,
    N_LAYERS: 8,
    DROPOUT_EMBEDDING_RATE: 0,
    DROPOUT_ATTENTION_RATE: 0,
    DROPOUT_SHORTCUT_RATE: 0,
    QKV_BIAS: False,
    DEFAULT_DATA_TYPE: torch.bfloat16,
    TOKENIZER_TYPE: "sentencepiece",
    TOKENIZER_NAME: "conversational-emotion-english-16k-lc-16000"
}

#30_807_450
CONV_ENG_LC_16K_CONFIG_XS_400_10L_10H_450E = {
    CONFIG_NAME: "CONV_ENG_LC_16K_CONFIG_XS_400_10L_10H_450E",
    VOCABULARY_SIZE: 16000,
    CONTEXT_LENGTH: 400,
    EMBEDDING_DIMENSION: 450,
    N_HEADS: 10,
    N_LAYERS: 10,
    DROPOUT_EMBEDDING_RATE: 0,
    DROPOUT_ATTENTION_RATE: 0,
    DROPOUT_SHORTCUT_RATE: 0,
    QKV_BIAS: False,
    DEFAULT_DATA_TYPE: torch.bfloat16,
    TOKENIZER_TYPE: "sentencepiece",
    TOKENIZER_NAME: "conversational-emotion-english-16k-lc-16000"
}

#27_562_050
CONV_ENG_LC_16K_CONFIG_XS_400_8L_10H_450E = {
    CONFIG_NAME: "CONV_ENG_LC_16K_CONFIG_XS_400_8L_10H_450E",
    VOCABULARY_SIZE: 16000,
    CONTEXT_LENGTH: 400,
    EMBEDDING_DIMENSION: 450,
    N_HEADS: 10,
    N_LAYERS: 8,
    DROPOUT_EMBEDDING_RATE: 0,
    DROPOUT_ATTENTION_RATE: 0,
    DROPOUT_SHORTCUT_RATE: 0,
    QKV_BIAS: False,
     TOKENIZER_TYPE: "sentencepiece",
    TOKENIZER_NAME: "conversational-emotion-english-16k-lc-16000"
}

#3_3m
CONV_ENG_LC_16K_CONFIG_XS_200_2L_5H_100E = {
    CONFIG_NAME: "CONV_ENG_LC_16K_CONFIG_XS_200_2L_5H_100E",
    VOCABULARY_SIZE: 16000,
    CONTEXT_LENGTH: 200,
    EMBEDDING_DIMENSION: 100,
    N_HEADS: 5,
    N_LAYERS: 2,
    DROPOUT_EMBEDDING_RATE: 0,
    DROPOUT_ATTENTION_RATE: 0,
    DROPOUT_SHORTCUT_RATE: 0,
    QKV_BIAS: False,
    DEFAULT_DATA_TYPE: torch.bfloat16,
    TOKENIZER_TYPE: "sentencepiece",
    TOKENIZER_NAME: "conversational-emotion-english-16k-lc-16000"
}

################################
# CONV_ENG_LC_12K
################################


#22_842_720
CONV_ENG_LC_12K_CONFIG_XS_512_6L_12H_480E = {
    CONFIG_NAME: "CONV_ENG_LC_12K_CONFIG_XS_512_6L_12H_480E",
    VOCABULARY_SIZE: 12000,
    CONTEXT_LENGTH: 512,
    EMBEDDING_DIMENSION: 480,
    N_HEADS: 12,
    N_LAYERS: 6,
    DROPOUT_EMBEDDING_RATE: 0,
    DROPOUT_ATTENTION_RATE: 0,
    DROPOUT_SHORTCUT_RATE: 0,
    QKV_BIAS: False,
    DEFAULT_DATA_TYPE: torch.bfloat16,
    TOKENIZER_TYPE: "sentencepiece",
    TOKENIZER_NAME: "conversational-english-12k-lc-12000"
}

#23_962_050
CONV_ENG_LC_12K_CONFIG_XS_400_8L_10H_450E = {
    CONFIG_NAME: "CONV_ENG_LC_12K_CONFIG_XS_400_8L_10H_450E",
    VOCABULARY_SIZE: 12000,
    CONTEXT_LENGTH: 400,
    EMBEDDING_DIMENSION: 450,
    N_HEADS: 10,
    N_LAYERS: 8,
    DROPOUT_EMBEDDING_RATE: 0,
    DROPOUT_ATTENTION_RATE: 0,
    DROPOUT_SHORTCUT_RATE: 0,
    QKV_BIAS: False,
    DEFAULT_DATA_TYPE: torch.bfloat16,
    TOKENIZER_TYPE: "sentencepiece",
    TOKENIZER_NAME: "conversational-english-12k-lc-12000"
}

#18_326_350
CONV_ENG_LC_12K_CONFIG_XS_300_10L_10H_350E = {
    CONFIG_NAME: "CONV_ENG_LC_12K_CONFIG_XS_300_10L_10H_350E",
    VOCABULARY_SIZE: 12000,
    CONTEXT_LENGTH: 300,
    EMBEDDING_DIMENSION: 350,
    N_HEADS: 10,
    N_LAYERS: 10,
    DROPOUT_EMBEDDING_RATE: 0,
    DROPOUT_ATTENTION_RATE: 0,
    DROPOUT_SHORTCUT_RATE: 0,
    QKV_BIAS: False,
    DEFAULT_DATA_TYPE: torch.bfloat16,
    TOKENIZER_TYPE: "sentencepiece",
    TOKENIZER_NAME: "conversational-english-12k-lc-12000"
}

#40_128_030
CONV_ENG_LC_12K_CONFIG_XS_400_20L_10H_430E = {
    CONFIG_NAME: "CONV_ENG_LC_12K_CONFIG_XS_400_20L_10H_430E",
    VOCABULARY_SIZE: 12000,
    CONTEXT_LENGTH: 400,
    EMBEDDING_DIMENSION: 430,
    N_HEADS: 10,
    N_LAYERS: 20,
    DROPOUT_EMBEDDING_RATE: 0,
    DROPOUT_ATTENTION_RATE: 0,
    DROPOUT_SHORTCUT_RATE: 0,
    QKV_BIAS: False,
    DEFAULT_DATA_TYPE: torch.bfloat16,
    TOKENIZER_TYPE: "sentencepiece",
    TOKENIZER_NAME: "conversational-english-12k-lc-12000"
}

#39_645_330
CONV_ENG_LC_12K_CONFIG_XS_300_6L_15H_690E = {
    CONFIG_NAME: "CONV_ENG_LC_12K_CONFIG_XS_300_6L_15H_690E",
    VOCABULARY_SIZE: 12000,
    CONTEXT_LENGTH: 300,
    EMBEDDING_DIMENSION: 690,
    N_HEADS: 15,
    N_LAYERS: 6,
    DROPOUT_EMBEDDING_RATE: 0,
    DROPOUT_ATTENTION_RATE: 0,
    DROPOUT_SHORTCUT_RATE: 0,
    QKV_BIAS: False,
    DEFAULT_DATA_TYPE: torch.bfloat16,
    TOKENIZER_TYPE: "sentencepiece",
    TOKENIZER_NAME: "conversational-english-12k-lc-12000"
}

# lamda 40_2-1 1
#40_217_500
CONV_ENG_LC_12K_CONFIG_XS_350_14L_10H_500E = {
    CONFIG_NAME: "CONV_ENG_LC_12K_CONFIG_XS_350_14L_10H_500E",
    VOCABULARY_SIZE: 12000,
    CONTEXT_LENGTH: 350,
    EMBEDDING_DIMENSION: 500,
    N_HEADS: 10,
    N_LAYERS: 14,
    DROPOUT_EMBEDDING_RATE: 0,
    DROPOUT_ATTENTION_RATE: 0,
    DROPOUT_SHORTCUT_RATE: 0,
    QKV_BIAS: False,
    DEFAULT_DATA_TYPE: torch.bfloat16,
    TOKENIZER_TYPE: "sentencepiece",
    TOKENIZER_NAME: "conversational-english-12k-lc-12000"
}

#52_260_500
CONV_ENG_LC_12K_CONFIG_XS_400_20L_10H_500E = {
    CONFIG_NAME: "CONV_ENG_LC_12K_CONFIG_XS_400_20L_10H_500E",
    VOCABULARY_SIZE: 12000,
    CONTEXT_LENGTH: 400,
    EMBEDDING_DIMENSION: 500,
    N_HEADS: 10,
    N_LAYERS: 20,
    DROPOUT_EMBEDDING_RATE: 0,
    DROPOUT_ATTENTION_RATE: 0,
    DROPOUT_SHORTCUT_RATE: 0,
    QKV_BIAS: False,
    DEFAULT_DATA_TYPE: torch.bfloat16,
    TOKENIZER_TYPE: "sentencepiece",
    TOKENIZER_NAME: "conversational-english-12k-lc-12000"
}

#52_310_500
CONV_ENG_LC_12K_CONFIG_XS_500_20L_10H_600E = {
    CONFIG_NAME: "CONV_ENG_LC_12K_CONFIG_XS_500_20L_10H_600E",
    VOCABULARY_SIZE: 12000,
    CONTEXT_LENGTH: 500,
    EMBEDDING_DIMENSION: 500,
    N_HEADS: 10,
    N_LAYERS: 20,
    DROPOUT_EMBEDDING_RATE: 0,
    DROPOUT_ATTENTION_RATE: 0,
    DROPOUT_SHORTCUT_RATE: 0,
    QKV_BIAS: False,
    DEFAULT_DATA_TYPE: torch.bfloat16,
    TOKENIZER_TYPE: "sentencepiece",
    TOKENIZER_NAME: "conversational-english-12k-lc-12000"
}

################################
# CONV_ENG_LC_8K
################################

#30_079_200
CONV_ENG_LC_8K_CONFIG_XS_512_12L_12H_480E = {
    CONFIG_NAME: "CONV_ENG_LC_8K_CONFIG_XS_512_12L_12H_480E",
    VOCABULARY_SIZE: 8000,
    CONTEXT_LENGTH: 512,
    EMBEDDING_DIMENSION: 480,
    N_HEADS: 12,
    N_LAYERS: 12,
    DROPOUT_EMBEDDING_RATE: 0,
    DROPOUT_ATTENTION_RATE: 0,
    DROPOUT_SHORTCUT_RATE: 0,
    QKV_BIAS: False,
    DEFAULT_DATA_TYPE: torch.bfloat16,
    TOKENIZER_TYPE: "sentencepiece",
    TOKENIZER_NAME: "conversational-english-8k-lc-8000"
}

#19_002_720
CONV_ENG_LC_8K_CONFIG_XS_512_6L_12H_480E = {
    CONFIG_NAME: "CONV_ENG_LC_8K_CONFIG_XS_512_6L_12H_480E",
    VOCABULARY_SIZE: 8000,
    CONTEXT_LENGTH: 512,
    EMBEDDING_DIMENSION: 480,
    N_HEADS: 12,
    N_LAYERS: 6,
    DROPOUT_EMBEDDING_RATE: 0,
    DROPOUT_ATTENTION_RATE: 0,
    DROPOUT_SHORTCUT_RATE: 0,
    QKV_BIAS: False,
    DEFAULT_DATA_TYPE: torch.bfloat16,
    TOKENIZER_TYPE: "sentencepiece",
    TOKENIZER_NAME: "conversational-english-8k-lc-8000"
}

#18_924_960
CONV_ENG_LC_8K_CONFIG_XS_350_6L_12H_480E = {
    CONFIG_NAME: "CONV_ENG_LC_8K_CONFIG_XS_350_6L_12H_480E",
    VOCABULARY_SIZE: 8000,
    CONTEXT_LENGTH: 350,
    EMBEDDING_DIMENSION: 480,
    N_HEADS: 12,
    N_LAYERS: 6,
    DROPOUT_EMBEDDING_RATE: 0,
    DROPOUT_ATTENTION_RATE: 0,
    DROPOUT_SHORTCUT_RATE: 0,
    QKV_BIAS: False,
    DEFAULT_DATA_TYPE: torch.bfloat16,
    TOKENIZER_TYPE: "sentencepiece",
    TOKENIZER_NAME: "conversational-english-8k-lc-8000"
}

#14_256_360
CONV_ENG_LC_8K_CONFIG_XS_512_8L_12H_360E = {
    CONFIG_NAME: "CONV_ENG_LC_8K_CONFIG_XS_512_8L_12H_360E",
    VOCABULARY_SIZE: 8000,
    CONTEXT_LENGTH: 512,
    EMBEDDING_DIMENSION: 360,
    N_HEADS: 12,
    N_LAYERS: 8,
    DROPOUT_EMBEDDING_RATE: 0,
    DROPOUT_ATTENTION_RATE: 0,
    DROPOUT_SHORTCUT_RATE: 0,
    QKV_BIAS: False,
    DEFAULT_DATA_TYPE: torch.bfloat16,
    TOKENIZER_TYPE: "sentencepiece",
    TOKENIZER_NAME: "conversational-english-8k-lc-8000"
}

#12_875_856
CONV_ENG_LC_8K_CONFIG_XS_768_8L_12H_336E = {
    CONFIG_NAME: "CONV_ENG_LC_8K_CONFIG_XS_768_8L_12H_336E",
    VOCABULARY_SIZE: 8000,
    CONTEXT_LENGTH: 768,
    EMBEDDING_DIMENSION: 336,
    N_HEADS: 12,
    N_LAYERS: 8,
    DROPOUT_EMBEDDING_RATE: 0,
    DROPOUT_ATTENTION_RATE: 0,
    DROPOUT_SHORTCUT_RATE: 0,
    QKV_BIAS: False,
    DEFAULT_DATA_TYPE: torch.bfloat16,
    TOKENIZER_TYPE: "sentencepiece",
    TOKENIZER_NAME: "conversational-english-8k-lc-8000"
}

#12_108_300
CONV_ENG_LC_8K_CONFIG_XS_300_10L_10H_300E = {
    CONFIG_NAME: "CONV_ENG_LC_8K_CONFIG_XS_300_10L_10H_300E",
    VOCABULARY_SIZE: 8000,
    CONTEXT_LENGTH: 300,
    EMBEDDING_DIMENSION: 300,
    N_HEADS: 10,
    N_LAYERS: 10,
    DROPOUT_EMBEDDING_RATE: 0,
    DROPOUT_ATTENTION_RATE: 0,
    DROPOUT_SHORTCUT_RATE: 0,
    QKV_BIAS: False,
    DEFAULT_DATA_TYPE: torch.bfloat16,
    TOKENIZER_TYPE: "sentencepiece",
    TOKENIZER_NAME: "conversational-english-8k-lc-8000"
}

#8_499_300
CONV_ENG_LC_8K_CONFIG_XS_300_5L_5H_300E = {
    CONFIG_NAME: "CONV_ENG_LC_8K_CONFIG_XS_300_5L_5H_300E",
    VOCABULARY_SIZE: 8000,
    CONTEXT_LENGTH: 300,
    EMBEDDING_DIMENSION: 300,
    N_HEADS: 5,
    N_LAYERS: 5,
    DROPOUT_EMBEDDING_RATE: 0,
    DROPOUT_ATTENTION_RATE: 0,
    DROPOUT_SHORTCUT_RATE: 0,
    QKV_BIAS: False,
    DEFAULT_DATA_TYPE: torch.bfloat16,
    TOKENIZER_TYPE: "sentencepiece",
    TOKENIZER_NAME: "conversational-english-8k-lc-8000"
}

#3_349_650
CONV_ENG_LC_8K_CONFIG_XS_300_5L_5H_150E = {
    CONFIG_NAME: "CONV_ENG_LC_8K_CONFIG_XS_300_5L_5H_150E",
    VOCABULARY_SIZE: 8000,
    CONTEXT_LENGTH: 300,
    EMBEDDING_DIMENSION: 150,
    N_HEADS: 5,
    N_LAYERS: 5,
    DROPOUT_EMBEDDING_RATE: 0,
    DROPOUT_ATTENTION_RATE: 0,
    DROPOUT_SHORTCUT_RATE: 0,
    QKV_BIAS: False,
    DEFAULT_DATA_TYPE: torch.bfloat16,
    TOKENIZER_TYPE: "sentencepiece",
    TOKENIZER_NAME: "conversational-english-8k-lc-8000"
}

#1_056_540
CONV_ENG_LC_8K_CONFIG_XS_150_3L_6H_60E = {
    CONFIG_NAME: "CONV_ENG_LC_8K_CONFIG_XS_150_3L_6H_60E",
    VOCABULARY_SIZE: 8000,
    CONTEXT_LENGTH: 150,
    EMBEDDING_DIMENSION: 60,
    N_HEADS: 6,
    N_LAYERS: 3,
    DROPOUT_EMBEDDING_RATE: 0,
    DROPOUT_ATTENTION_RATE: 0,
    DROPOUT_SHORTCUT_RATE: 0,
    QKV_BIAS: False,
    DEFAULT_DATA_TYPE: torch.bfloat16,
    TOKENIZER_TYPE: "sentencepiece",
    TOKENIZER_NAME: "conversational-english-8k-lc-8000"
}

#36_688_030
CONV_ENG_LC_8K_CONFIG_XS_400_20L_10H_430E = {
    CONFIG_NAME: "CONV_ENG_LC_8K_CONFIG_XS_400_20L_10H_430E",
    VOCABULARY_SIZE: 8000,
    CONTEXT_LENGTH: 400,
    EMBEDDING_DIMENSION: 430,
    N_HEADS: 10,
    N_LAYERS: 20,
    DROPOUT_EMBEDDING_RATE: 0,
    DROPOUT_ATTENTION_RATE: 0,
    DROPOUT_SHORTCUT_RATE: 0,
    QKV_BIAS: False,
    DEFAULT_DATA_TYPE: torch.bfloat16,
    TOKENIZER_TYPE: "sentencepiece",
    TOKENIZER_NAME: "conversational-english-8k-lc-12000"
}

################################
# GPT
################################

GPT_CONFIG_SMALL = {
    CONFIG_NAME: "GPT_CONFIG_SMALL",
    VOCABULARY_SIZE: 50257,
    CONTEXT_LENGTH: 1024,
    EMBEDDING_DIMENSION: 768,
    N_HEADS: 12,
    N_LAYERS: 12,
    DROPOUT_EMBEDDING_RATE: 0,
    DROPOUT_ATTENTION_RATE: 0,
    DROPOUT_SHORTCUT_RATE: 0,
    QKV_BIAS: False,
    DEFAULT_DATA_TYPE: torch.float32,
    TOKENIZER_TYPE: "gpt2",
    TOKENIZER_NAME: None
}

GPT_CONFIG_124M = GPT_CONFIG_SMALL
GPT_CONFIG_124M[CONFIG_NAME] = "GPT_CONFIG_124M"

GPT_CONFIG_MEDIUM = {
    CONFIG_NAME: "GPT_CONFIG_MEDIUM",
    VOCABULARY_SIZE: 50257,
    CONTEXT_LENGTH: 1024,
    EMBEDDING_DIMENSION: 1024,
    N_HEADS: 16,
    N_LAYERS: 24,
    DROPOUT_EMBEDDING_RATE: 0,
    DROPOUT_ATTENTION_RATE: 0,
    DROPOUT_SHORTCUT_RATE: 0,
    QKV_BIAS: False,
    DEFAULT_DATA_TYPE: torch.float32,
    TOKENIZER_TYPE: "gpt2",
    TOKENIZER_NAME: None
}

GPT_CONFIG_LARGE = {
    CONFIG_NAME: "GPT_CONFIG_LARGE",
    VOCABULARY_SIZE: 50257,
    CONTEXT_LENGTH: 1024,
    EMBEDDING_DIMENSION: 1280,
    N_HEADS: 20,
    N_LAYERS: 36,
    DROPOUT_EMBEDDING_RATE: 0,
    DROPOUT_ATTENTION_RATE: 0,
    DROPOUT_SHORTCUT_RATE: 0,
    QKV_BIAS: False,
    DEFAULT_DATA_TYPE: torch.float32,
    TOKENIZER_TYPE: "gpt2",
    TOKENIZER_NAME: None
}


GPT_CONFIG_X_LARGE = {
    CONFIG_NAME: "GPT_CONFIG_X_LARGE",
    VOCABULARY_SIZE: 50257,
    CONTEXT_LENGTH: 1024,
    EMBEDDING_DIMENSION: 1600,
    N_HEADS: 25,
    N_LAYERS: 48,
    DROPOUT_EMBEDDING_RATE: 0,
    DROPOUT_ATTENTION_RATE: 0,
    DROPOUT_SHORTCUT_RATE: 0,
    QKV_BIAS: False,
    DEFAULT_DATA_TYPE: torch.float32,
    TOKENIZER_TYPE: "gpt2",
    TOKENIZER_NAME: None
}

modelConfigs = {
    # GPT
    "GPT_CONFIG_SMALL":GPT_CONFIG_SMALL,
    "GPT_CONFIG_124M":GPT_CONFIG_124M,
    "GPT_CONFIG_MEDIUM":GPT_CONFIG_MEDIUM,
    "GPT_CONFIG_LARGE":GPT_CONFIG_LARGE,
    "GPT_CONFIG_X_LARGE":GPT_CONFIG_X_LARGE,

    #CONV_ENG_8K_LC
    "CONV_ENG_LC_8K_CONFIG_XS_768_8L_12H_336E": CONV_ENG_LC_8K_CONFIG_XS_768_8L_12H_336E,
    "CONV_ENG_LC_8K_CONFIG_XS_300_5L_5H_150E": CONV_ENG_LC_8K_CONFIG_XS_300_5L_5H_150E,
    "CONV_ENG_LC_8K_CONFIG_XS_300_5L_5H_300E": CONV_ENG_LC_8K_CONFIG_XS_300_5L_5H_300E, 
    "CONV_ENG_LC_8K_CONFIG_XS_300_10L_10H_300E": CONV_ENG_LC_8K_CONFIG_XS_300_10L_10H_300E,
    "CONV_ENG_LC_8K_CONFIG_XS_150_3L_6H_60E": CONV_ENG_LC_8K_CONFIG_XS_150_3L_6H_60E,
    "CONV_ENG_LC_8K_CONFIG_XS_350_6L_12H_480E": CONV_ENG_LC_8K_CONFIG_XS_350_6L_12H_480E,
    "CONV_ENG_LC_8K_CONFIG_XS_512_6L_12H_480E": CONV_ENG_LC_8K_CONFIG_XS_512_6L_12H_480E,
    "CONV_ENG_LC_8K_CONFIG_XS_512_8L_12H_360E": CONV_ENG_LC_8K_CONFIG_XS_512_8L_12H_360E,
    "CONV_ENG_LC_8K_CONFIG_XS_512_12L_12H_480E": CONV_ENG_LC_8K_CONFIG_XS_512_12L_12H_480E, 
    "CONV_ENG_LC_8K_CONFIG_XS_400_20L_10H_430E": CONV_ENG_LC_8K_CONFIG_XS_400_20L_10H_430E, 

    #CONV_ENG_12K_LC
    "CONV_ENG_LC_12K_CONFIG_XS_512_6L_12H_480E": CONV_ENG_LC_12K_CONFIG_XS_512_6L_12H_480E,
    "CONV_ENG_LC_12K_CONFIG_XS_300_10L_10H_350E": CONV_ENG_LC_12K_CONFIG_XS_300_10L_10H_350E,
    "CONV_ENG_LC_12K_CONFIG_XS_400_20L_10H_430E": CONV_ENG_LC_12K_CONFIG_XS_400_20L_10H_430E,    
    "CONV_ENG_LC_12K_CONFIG_XS_300_6L_15H_690E": CONV_ENG_LC_12K_CONFIG_XS_300_6L_15H_690E,
    "CONV_ENG_LC_12K_CONFIG_XS_350_14L_10H_500E": CONV_ENG_LC_12K_CONFIG_XS_350_14L_10H_500E, 
    "CONV_ENG_LC_12K_CONFIG_XS_400_20L_10H_500E": CONV_ENG_LC_12K_CONFIG_XS_400_20L_10H_500E,
    "CONV_ENG_LC_12K_CONFIG_XS_500_20L_10H_600E": CONV_ENG_LC_12K_CONFIG_XS_500_20L_10H_600E, 
    "CONV_ENG_LC_12K_CONFIG_XS_400_8L_10H_450E": CONV_ENG_LC_12K_CONFIG_XS_400_8L_10H_450E,

    #CONV_ENG_16K_LC
    "CONV_ENG_LC_16K_CONFIG_XS_200_2L_5H_100E": CONV_ENG_LC_16K_CONFIG_XS_200_2L_5H_100E, 
    "CONV_ENG_LC_16K_CONFIG_XS_400_8L_10H_450E": CONV_ENG_LC_16K_CONFIG_XS_400_8L_10H_450E,
    "CONV_ENG_LC_16K_CONFIG_XS_400_10L_10H_450E": CONV_ENG_LC_16K_CONFIG_XS_400_10L_10H_450E,
    "CONV_ENG_LC_16K_CONFIG_XS_500_24L_8H_256E": CONV_ENG_LC_16K_CONFIG_XS_500_24L_8H_256E,
    "CONV_ENG_LC_16K_CONFIG_XS_400_8L_8H_512E": CONV_ENG_LC_16K_CONFIG_XS_400_8L_8H_512E,
    "CONV_ENG_LC_16K_CONFIG_XS_500_8L_16H_512E": CONV_ENG_LC_16K_CONFIG_XS_500_8L_16H_512E,
    "CONV_ENG_LC_16K_CONFIG_XS_500_20L_10H_550E": CONV_ENG_LC_16K_CONFIG_XS_500_20L_10H_550E,
    "CONV_ENG_LC_16K_CONFIG_XS_500_15L_10H_750E": CONV_ENG_LC_16K_CONFIG_XS_500_15L_10H_750E
}

def getDataTypeFromConfig(config): 
    # https://medium.com/data-science/pytorch-native-fp8-fedc06f1c9f7
    dt = torch.float32
    cfgDt = config[DEFAULT_DATA_TYPE]
    if cfgDt == 'bfloat16':
        dt = torch.bfloat16
    elif cfgDt == 'float16':
        dt = torch.float16
    elif cfgDt == 'float8_e4m3fn':
        dt = torch.float8_e4m3fn
    elif cfgDt == 'float8_e4m3fnuz':
        dt = torch.float8_e4m3fnuz
    elif cfgDt == 'float8_e5m2':
        dt = torch.float8_e5m2
    elif cfgDt == 'float8_e5m2fnuz':
        dt = torch.float8_e5m2fnuz
    elif cfgDt == 'float8_e8m0fnu':
        dt = torch.float8_e8m0fnu   

    return dt
